{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 2: Features vector\n",
    "\n",
    "## Manual categorization of the dictionary \n",
    "\n",
    "This dictionary expands sections into categories applied in Data Story folder. Criteria to label phrases is the same, but now three new sections are included: **price** (on category place), **snacks** (on food category) and **do** (on category place, including *study, work, talking with friends, hanging* and elements associated as *laptop, wifi, books*). The name **decoration** is replaced for **ambient** because this topic includes **decoration**, **size** of the business, **music**; and **go** includes the categories **to here**, **to go** (previoulsy used in Data Story) and all the elements associated with the possibility or not of find a set, grab the coffee to sit or to go, how crowded is the place, availability of tables and **out** is related to the view, neighborhood, parking. \n",
    "\n",
    "Definitive 3 categories and 16 sections are listed below:\n",
    "\n",
    "1. **Coffee**: *Baristas, Roasting, Beans, Drinks, Sentiment*\n",
    "\n",
    "2. **Place**: *Ambient, Go, Do, Out (outside), Sentiment, Price*\n",
    "\n",
    "3. **Food**: *Sentiment, Breakfast, Baked, Lunch, Snacks*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building feature vectors\n",
    "\n",
    "1. **Similarity vectors**\n",
    "\n",
    "Joining these key-words group by sections, we build topic documents of every section and we split the customer reviews (paragraphs) into sentences to looking for the similarity between the topic documents with every sentence using cosine similarity. In this way, we have reviews split into sentences and every sentence is represented as a vector with 16 features with the similarity score between the sentence and every topic document, called **Similarity feature vector**.\n",
    "\n",
    "2. **Polarity vectors**\n",
    "\n",
    "Additionally, the polarity pattern of every sentence is computed and rescaled to have values between 0 and 1 instead -1 and 1. We did that because, as we noted in the previous analysis, neutral sentences are frequent and they have a polarity pattern around 0. Multiplying the original polarity scores by the similarity scores cancels a lot of values in every feature and we potentially could lose a lot of information. Finally, the vectors of sentences are group by review and aggregated using the mean of all the components, to build one vector for review with 16 features, corresponding to a ponderation between the similarity and the polarity of the topics presents on the review. These vectors of polarity are called **Polarity features vectors**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing relevant packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import nltk\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from textblob.sentiments import PatternAnalyzer\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing vocabulary categorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape = (5378, 4) and shape after to delete NaN categories and sections = (1267, 4)\n"
     ]
    }
   ],
   "source": [
    "df_all = pd.read_csv('../Machine_Learning/preprocessing_ml/tfidf_vocab_categorized.csv')\n",
    "df = df_all.dropna()\n",
    "print('Original shape = {} and shape after to delete NaN categories and sections = {}'.format(df_all.shape, df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key_words</th>\n",
       "      <th>key_values</th>\n",
       "      <th>category</th>\n",
       "      <th>section</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>fifthgeneration baker</td>\n",
       "      <td>0.07</td>\n",
       "      <td>food</td>\n",
       "      <td>baked</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>tea decent</td>\n",
       "      <td>0.07</td>\n",
       "      <td>coffee</td>\n",
       "      <td>drinks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>tea said</td>\n",
       "      <td>0.07</td>\n",
       "      <td>coffee</td>\n",
       "      <td>drinks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>bouncy crunchy</td>\n",
       "      <td>0.07</td>\n",
       "      <td>food</td>\n",
       "      <td>baked</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>buttery lot</td>\n",
       "      <td>0.07</td>\n",
       "      <td>food</td>\n",
       "      <td>baked</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                key_words key_values category section\n",
       "11  fifthgeneration baker       0.07     food   baked\n",
       "17             tea decent       0.07   coffee  drinks\n",
       "18               tea said       0.07   coffee  drinks\n",
       "23         bouncy crunchy       0.07     food   baked\n",
       "25            buttery lot       0.07     food   baked"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to transform key-words in documents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(s): \n",
    "    # initialization of string to \"\" \n",
    "    new = \"\" \n",
    "    # traverse in the string  \n",
    "    for x in s: \n",
    "        new += x+' '\n",
    "    # return string  \n",
    "    return new "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspecting data group by categories and sections:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_food = df[df.category == 'food']\n",
    "df_coffee = df[df.category == 'coffee']\n",
    "df_place = df[df.category == 'place']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(373, 4) (341, 4) (553, 4)\n"
     ]
    }
   ],
   "source": [
    "print(df_food.shape, df_coffee.shape, df_place.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key_words</th>\n",
       "      <th>key_values</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>section</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>baked</th>\n",
       "      <td>115</td>\n",
       "      <td>115</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>breakfast</th>\n",
       "      <td>102</td>\n",
       "      <td>102</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lunch</th>\n",
       "      <td>85</td>\n",
       "      <td>85</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentiment</th>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>snacks</th>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           key_words  key_values  category\n",
       "section                                   \n",
       "baked            115         115       115\n",
       "breakfast        102         102       102\n",
       "lunch             85          85        85\n",
       "sentiment         50          50        50\n",
       "snacks            21          21        21"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_food.groupby('section').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key_words</th>\n",
       "      <th>key_values</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>section</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>barista</th>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beans</th>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>drinks</th>\n",
       "      <td>174</td>\n",
       "      <td>174</td>\n",
       "      <td>174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roast</th>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentiment</th>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           key_words  key_values  category\n",
       "section                                   \n",
       "barista           65          65        65\n",
       "beans             40          40        40\n",
       "drinks           174         174       174\n",
       "roast             33          33        33\n",
       "sentiment         29          29        29"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_coffee.groupby('section').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key_words</th>\n",
       "      <th>key_values</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>section</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>decoration</th>\n",
       "      <td>142</td>\n",
       "      <td>142</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>do</th>\n",
       "      <td>84</td>\n",
       "      <td>84</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>go</th>\n",
       "      <td>91</td>\n",
       "      <td>91</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>out</th>\n",
       "      <td>114</td>\n",
       "      <td>114</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentiment</th>\n",
       "      <td>102</td>\n",
       "      <td>102</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            key_words  key_values  category\n",
       "section                                    \n",
       "decoration        142         142       142\n",
       "do                 84          84        84\n",
       "go                 91          91        91\n",
       "out               114         114       114\n",
       "price              20          20        20\n",
       "sentiment         102         102       102"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_place.groupby('section').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transforming key-words in documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_coffee_beans = convert(df_coffee[df_coffee.section == 'beans'].key_words.tolist())\n",
    "doc_coffee_roast = convert(df_coffee[df_coffee.section == 'roast'].key_words.tolist())\n",
    "doc_coffee_drinks = convert(df_coffee[df_coffee.section == 'drinks'].key_words.tolist())\n",
    "doc_coffee_barista = convert(df_coffee[df_coffee.section == 'barista'].key_words.tolist())\n",
    "doc_coffee_sentiment = convert(df_coffee[df_coffee.section == 'sentiment'].key_words.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_place_go = convert(df_place[(df_place.section == 'go')].key_words.tolist())\n",
    "doc_place_do = convert(df_place[df_place.section == 'do'].key_words.tolist())\n",
    "doc_place_out = convert(df_place[df_place.section == 'out'].key_words.tolist())\n",
    "doc_place_price = convert(df_place[(df_place.section == 'price')].key_words.tolist())\n",
    "doc_place_ambient = convert(df_place[(df_place.section == 'decoration')].key_words.tolist())\n",
    "doc_place_sentiment = convert(df_place[df_place.section == 'sentiment'].key_words.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_food_baked = convert(df_food[df_food.section == 'baked'].key_words.tolist())\n",
    "doc_food_lunch = convert(df_food[df_food.section == 'lunch'].key_words.tolist())\n",
    "doc_food_breakfast = convert(df_food[df_food.section == 'breakfast'].key_words.tolist())\n",
    "doc_food_sentiment = convert(df_food[df_food.section == 'sentiment'].key_words.tolist())\n",
    "doc_food_snacks = convert(df_food[df_food.section == 'snacks'].key_words.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing reviews, changing the names duplicated on coffee shops of the same chain. One of our analysis pretend to cluster the coffee shops, this it is important to distinguish business with the same name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reviews = pd.read_csv(\"../Data_Extraction/Reviews/reviews_rating_date.csv\", \\\n",
    "                         usecols=['Coffee', 'Description','Rating', 'date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reviews.loc[20:40, 'Coffee'] = 'Coffee 1'\n",
    "df_reviews.loc[40:60, 'Coffee'] = 'Coffee 2'\n",
    "df_reviews.loc[60:80, 'Coffee'] = 'The Mill'\n",
    "df_reviews.loc[1939:1959, 'Coffee'] = 'The Mill 1'\n",
    "df_reviews.loc[1200:1220, 'Coffee'] = 'Andytown Coffee 1'\n",
    "df_reviews.loc[1691:1711, 'Coffee'] = 'Réveille Coffee 1'\n",
    "df_reviews.loc[340:360, 'Coffee'] = 'Sightglass 1'\n",
    "df_reviews.loc[780:800, 'Coffee'] = 'Sightglass 2'\n",
    "df_reviews.loc[2439:2459, 'Coffee'] = 'Sightglass 3'\n",
    "df_reviews.loc[940:960, 'Coffee'] = 'Saint Frank 2'\n",
    "df_reviews.loc[800:820, 'Coffee'] = 'Philz 1'\n",
    "df_reviews.loc[2739:2759, 'Coffee'] = 'Philz 2'\n",
    "df_reviews.loc[3228:3248, 'Coffee'] = 'Philz 3'\n",
    "df_reviews.loc[700:720, 'Coffee'] = 'Blue Bottle 1'\n",
    "df_reviews.loc[2119:2139, 'Coffee'] = 'Blue Bottle 2'\n",
    "df_reviews.loc[2499:2519, 'Coffee'] = 'Blue Bottle 3'\n",
    "df_reviews.loc[2299:2319, 'Coffee'] = 'Jane on 1'\n",
    "df_reviews.loc[2159:2179, 'Coffee'] = 'Equator Coffees & 1'\n",
    "df_reviews.loc[2399:2419, 'Coffee'] = 'Equator Coffees & 2'\n",
    "df_reviews.loc[3172:3192 , 'Coffee'] = 'Contraband Coffee 1'\n",
    "df_reviews.loc[2859:2879, 'Coffee'] = 'Little 1'\n",
    "df_reviews.loc[1471:1491, 'Coffee'] = 'Cafe 1'\n",
    "df_reviews.loc[2599:2619, 'Coffee'] = 'Cafe 2'\n",
    "df_reviews.loc[2962:2982, 'Coffee'] = 'Cafe 3'\n",
    "df_reviews.loc[3122:3132, 'Coffee'] = 'Bluestone 1'\n",
    "df_reviews.loc[3528:3548, 'Coffee'] = 'Red Door 1'\n",
    "df_reviews.loc[2339:2359, 'Coffee'] = 'Martha & Brothers 1'\n",
    "df_reviews.loc[3042:3062, 'Coffee'] = 'Boba 1'\n",
    "df_reviews.loc[3102:3122, 'Coffee'] = 'Boba 2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coffee</th>\n",
       "      <th>Description</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rating</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1.0 star rating</th>\n",
       "      <td>246</td>\n",
       "      <td>263</td>\n",
       "      <td>263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0 star rating</th>\n",
       "      <td>196</td>\n",
       "      <td>207</td>\n",
       "      <td>207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0 star rating</th>\n",
       "      <td>309</td>\n",
       "      <td>327</td>\n",
       "      <td>327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0 star rating</th>\n",
       "      <td>780</td>\n",
       "      <td>821</td>\n",
       "      <td>821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0 star rating</th>\n",
       "      <td>1780</td>\n",
       "      <td>1930</td>\n",
       "      <td>1930</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Coffee  Description  date\n",
       "Rating                                    \n",
       "1.0 star rating     246          263   263\n",
       "2.0 star rating     196          207   207\n",
       "3.0 star rating     309          327   327\n",
       "4.0 star rating     780          821   821\n",
       "5.0 star rating    1780         1930  1930"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reviews.groupby('Rating').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we are dealing with polarity patterns, we must expect to have a proportion similar between negative and positive patterns and it make sense use samples randomly selected of reviews of 4 and 5 stars in a range of 200-300. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_ = df_reviews[df_reviews['Rating'] == '1.0 star rating']\n",
    "df2_ = df_reviews[df_reviews['Rating'] == '2.0 star rating']\n",
    "df3_ = df_reviews[df_reviews['Rating'] == '3.0 star rating']\n",
    "df4_ = df_reviews[df_reviews['Rating'] == '4.0 star rating']\n",
    "df5_ = df_reviews[df_reviews['Rating'] == '5.0 star rating']\n",
    "\n",
    "df4_sample = df4_.sample(n=200, random_state=42)\n",
    "df5_sample = df5_.sample(n=200, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([df1_, df2_, df3_, df4_sample, df5_sample], sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre-processing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "from http://stackoverflow.com/questions/19790188/expanding-english-language-contractions-in-python\n",
    "all credits go to alko and arturomp @ stack overflow.\n",
    "\"\"\"\n",
    "\n",
    "with open('../Data_Story/wordLists/contractionList.txt', 'r') as f:\n",
    "    cList = json.loads(f.read())\n",
    "    c_re = re.compile('(%s)' % '|'.join(cList.keys()))\n",
    "\n",
    "def expandContractions(text, c_re=c_re):\n",
    "    def replace(match):\n",
    "        return cList[match.group(0)]\n",
    "    return c_re.sub(replace, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = []\n",
    "with open('../Data_Story/wordLists/stop_wordsList.txt') as f:\n",
    "    stop_words = f.read().rstrip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "wpt = nltk.WordPunctTokenizer()\n",
    "lemmatizer = WordNetLemmatizer() \n",
    "\n",
    "def pre_processing(text):\n",
    "    # Normalize constractions and apply expansion of Constractions\n",
    "    text = re.sub(r'’',\"'\", text)\n",
    "    text = expandContractions(text.lower())\n",
    "    # Filtering special characters\n",
    "    text = re.sub(r'[^a-zA-Z\\s]','', text)\n",
    "    # Tokenization and filtering stop-words\n",
    "    tokens = wpt.tokenize(text)\n",
    "    words = [word for word in tokens if word not in stop_words]\n",
    "    # Lemmatization\n",
    "    words_lem = [lemmatizer.lemmatize(word) for word in words]\n",
    "    text_norm = ' '.join(words_lem)\n",
    "    \n",
    "    return text_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building Similarity features vectors\n",
    "\n",
    "1. Building a dictionary with the 16 documents of coffee topics\n",
    "2. Defining a function to build vectors from text using CountVectorizer\n",
    "3. Defining a function to compute similarity as the cosine of two input vectors.\n",
    "4. Iterating in reviews split into sentences to calculate the similarity score of every sentences with the 16 topics (features) to build the **Similarity features vectors**. \n",
    "5. Filtering the sentences with 0 similarity score in all the features (sum of the scores is 0)\n",
    "6. Saving the features in the dataFrame *df_similarity* in folder **preprocessing_ml** as a CSV file called **similarity_features_vectors.csv**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dictionary of documents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = {\n",
    "           'beans' : doc_coffee_beans,\n",
    "           'roast' : doc_coffee_roast,\n",
    "           'drinks' : doc_coffee_drinks,\n",
    "           'barista' : doc_coffee_barista,\n",
    "           'coffee sentiment' : doc_coffee_sentiment,\n",
    "           'go' : doc_place_go,\n",
    "           'do' : doc_place_do,\n",
    "           'out' : doc_place_out,\n",
    "           'ambient': doc_place_ambient,\n",
    "           'price' : doc_place_price,\n",
    "           'place sentiment' : doc_place_sentiment,\n",
    "           'baked' : doc_food_baked,\n",
    "           'lunch' : doc_food_lunch,\n",
    "           'breakfast' : doc_food_breakfast,\n",
    "           'snacks' : doc_food_snacks,\n",
    "           'food sentiment' : doc_food_sentiment\n",
    "            }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarity functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cosine_sim(*strs): \n",
    "    vectors = [t for t in get_vectors(*strs)]\n",
    "    return cosine_similarity(vectors)[0, 1]\n",
    "    \n",
    "def get_vectors(*strs):\n",
    "    text = [t for t in strs]\n",
    "    vectorizer = CountVectorizer(text)\n",
    "    vectorizer.fit(text)\n",
    "    v = vectorizer.transform(text).toarray()\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_similarities(documents, s1):\n",
    "    # Return the similarities (score and name of the topic)\n",
    "    score, topic = [], []\n",
    "\n",
    "    for key, doc in documents.items():\n",
    "        score.append(get_cosine_sim(s1, doc))\n",
    "        topic.append(key)\n",
    "    \n",
    "    return topic, score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the similarity between sentences and documents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_review = []\n",
    "coffee = []\n",
    "rating = []\n",
    "date = []\n",
    "sentence = []\n",
    "beans = []\n",
    "roast = []\n",
    "drinks = []\n",
    "barista = []\n",
    "coffee_sentiment = []\n",
    "go = []\n",
    "price = []\n",
    "do = []\n",
    "out = []\n",
    "ambient = []\n",
    "place_sentiment = []\n",
    "baked = []\n",
    "lunch = []\n",
    "breakfast = []\n",
    "snacks = []\n",
    "food_sentiment = []\n",
    "\n",
    "for idx, review in enumerate(data.Description): \n",
    "    coffee_el = data.Coffee[idx]\n",
    "    rating_el = data.Rating[idx]\n",
    "    date_el = data.date[idx]\n",
    "    idx_el = idx\n",
    "    for s in review.split('.'):\n",
    "        coffee.append(coffee_el)\n",
    "        rating.append(rating_el)\n",
    "        date.append(date_el)\n",
    "        id_review.append(idx_el)\n",
    "        a, b = find_similarities(documents, pre_processing(s))\n",
    "        beans.append(b[0])\n",
    "        roast.append(b[1])\n",
    "        drinks.append(b[2])\n",
    "        barista.append(b[3])\n",
    "        coffee_sentiment.append(b[4])\n",
    "        go.append(b[5])\n",
    "        do.append(b[6])\n",
    "        out.append(b[7])\n",
    "        ambient.append(b[8])\n",
    "        price.append(b[9])\n",
    "        place_sentiment.append(b[10])\n",
    "        baked.append(b[11])\n",
    "        lunch.append(b[12])\n",
    "        breakfast.append(b[13])\n",
    "        snacks.append(b[14])\n",
    "        food_sentiment.append(b[15])\n",
    "        sentence.append(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building a dataFrame of similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_similarity = pd.DataFrame({'id review' : id_review,\n",
    "                              'coffee' : coffee,\n",
    "                              'rating' : rating,\n",
    "                              'date' : date,\n",
    "                              'beans' : beans,\n",
    "                              'roast' : roast,\n",
    "                              'drinks' : drinks,\n",
    "                              'barista' : barista,\n",
    "                              'coffee_sentiment' : coffee_sentiment,\n",
    "                              'go' : go,\n",
    "                              'do' : do,\n",
    "                              'out' : out,\n",
    "                              'ambient' : ambient,\n",
    "                              'price' : price,\n",
    "                              'place_sentiment' : place_sentiment,\n",
    "                              'baked' : baked,\n",
    "                              'lunch' : lunch,\n",
    "                              'breakfast' : breakfast,\n",
    "                              'snacks' : snacks,\n",
    "                              'food_sentiment' : food_sentiment,\n",
    "                              'sentence_normalized' : sentence\n",
    "                              })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtering null similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7197, 22)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_similarity['sum'] = df_similarity.loc[:, 'beans':'food_sentiment'].sum(axis=1)\n",
    "df_similarity_filter = df_similarity[df_similarity['sum']>0]\n",
    "df_similarity_filter.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_similarity_copy = df_similarity_filter.copy()\n",
    "df_sc = df_similarity_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id review</th>\n",
       "      <th>coffee</th>\n",
       "      <th>rating</th>\n",
       "      <th>date</th>\n",
       "      <th>beans</th>\n",
       "      <th>roast</th>\n",
       "      <th>drinks</th>\n",
       "      <th>barista</th>\n",
       "      <th>coffee_sentiment</th>\n",
       "      <th>go</th>\n",
       "      <th>...</th>\n",
       "      <th>ambient</th>\n",
       "      <th>price</th>\n",
       "      <th>place_sentiment</th>\n",
       "      <th>baked</th>\n",
       "      <th>lunch</th>\n",
       "      <th>breakfast</th>\n",
       "      <th>snacks</th>\n",
       "      <th>food_sentiment</th>\n",
       "      <th>sentence_normalized</th>\n",
       "      <th>sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Réveille Coffee</td>\n",
       "      <td>1.0 star rating</td>\n",
       "      <td>4/16/2019</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.026689</td>\n",
       "      <td>0.013172</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.028212</td>\n",
       "      <td>...</td>\n",
       "      <td>0.050878</td>\n",
       "      <td>0.028748</td>\n",
       "      <td>0.240632</td>\n",
       "      <td>0.051900</td>\n",
       "      <td>0.027582</td>\n",
       "      <td>0.046318</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Folks, avoid this place unless you like being ...</td>\n",
       "      <td>0.643034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Réveille Coffee</td>\n",
       "      <td>1.0 star rating</td>\n",
       "      <td>4/16/2019</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.021167</td>\n",
       "      <td>0.029506</td>\n",
       "      <td>0.029123</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022499</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019126</td>\n",
       "      <td>0.076232</td>\n",
       "      <td>0.025603</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.097037</td>\n",
       "      <td>I went for a quick cappuccino only since they...</td>\n",
       "      <td>0.343937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Réveille Coffee</td>\n",
       "      <td>1.0 star rating</td>\n",
       "      <td>4/16/2019</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.036137</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.025466</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015679</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>The girl behind the counter walked over and s...</td>\n",
       "      <td>0.077282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>Réveille Coffee</td>\n",
       "      <td>1.0 star rating</td>\n",
       "      <td>4/16/2019</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031296</td>\n",
       "      <td>0.030890</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>I said hello</td>\n",
       "      <td>0.062186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>Réveille Coffee</td>\n",
       "      <td>1.0 star rating</td>\n",
       "      <td>4/16/2019</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.056433</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>again nothing but a stare</td>\n",
       "      <td>0.056433</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id review           coffee           rating       date  beans     roast  \\\n",
       "0          0  Réveille Coffee  1.0 star rating  4/16/2019    0.0  0.000000   \n",
       "1          0  Réveille Coffee  1.0 star rating  4/16/2019    0.0  0.021167   \n",
       "2          0  Réveille Coffee  1.0 star rating  4/16/2019    0.0  0.000000   \n",
       "6          0  Réveille Coffee  1.0 star rating  4/16/2019    0.0  0.000000   \n",
       "9          0  Réveille Coffee  1.0 star rating  4/16/2019    0.0  0.000000   \n",
       "\n",
       "     drinks   barista  coffee_sentiment        go    ...      ambient  \\\n",
       "0  0.026689  0.013172               0.0  0.028212    ...     0.050878   \n",
       "1  0.029506  0.029123               0.0  0.000000    ...     0.022499   \n",
       "2  0.036137  0.000000               0.0  0.025466    ...     0.000000   \n",
       "6  0.031296  0.030890               0.0  0.000000    ...     0.000000   \n",
       "9  0.000000  0.000000               0.0  0.000000    ...     0.000000   \n",
       "\n",
       "      price  place_sentiment     baked     lunch  breakfast  snacks  \\\n",
       "0  0.028748         0.240632  0.051900  0.027582   0.046318     0.0   \n",
       "1  0.000000         0.000000  0.019126  0.076232   0.025603     0.0   \n",
       "2  0.000000         0.000000  0.000000  0.000000   0.015679     0.0   \n",
       "6  0.000000         0.000000  0.000000  0.000000   0.000000     0.0   \n",
       "9  0.000000         0.056433  0.000000  0.000000   0.000000     0.0   \n",
       "\n",
       "   food_sentiment                                sentence_normalized       sum  \n",
       "0        0.000000  Folks, avoid this place unless you like being ...  0.643034  \n",
       "1        0.097037   I went for a quick cappuccino only since they...  0.343937  \n",
       "2        0.000000   The girl behind the counter walked over and s...  0.077282  \n",
       "6        0.000000                                       I said hello  0.062186  \n",
       "9        0.000000                          again nothing but a stare  0.056433  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_similarity_copy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the dataFrame in the folder **preprocessing_ml** as **similarity_features_vectors.csv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_sc.to_csv('preprocessing_ml/similarity_features_vectors.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building Polarity features vectors\n",
    "\n",
    "1. We use the normalized sentences to measure the polarity of every sentence\n",
    "2. Rescale the polarity patterns from (-1, 1) to (0, 1).\n",
    "3. Weighting the features using the polarity pattern in every sentence.\n",
    "4. Group sentences by id review using the mean of score of every feature. The feature vector is finally a review described for the topics mentioned into the review weighted by how strong is the similarity between the sentence and the coffee topics and the polarity of the message."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining sentiment analysis function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_parameters_Pattern(sentence):\n",
    "    blob = TextBlob(sentence, analyzer=PatternAnalyzer())\n",
    "    return blob.sentiment.polarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing polarity pattern:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "polarity = []\n",
    "for sentence in df_sc['sentence_normalized']:\n",
    "    polarity.append(sentiment_parameters_Pattern(sentence))\n",
    "    \n",
    "df_sc['polarity'] = polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id review</th>\n",
       "      <th>coffee</th>\n",
       "      <th>rating</th>\n",
       "      <th>date</th>\n",
       "      <th>beans</th>\n",
       "      <th>roast</th>\n",
       "      <th>drinks</th>\n",
       "      <th>barista</th>\n",
       "      <th>coffee_sentiment</th>\n",
       "      <th>go</th>\n",
       "      <th>...</th>\n",
       "      <th>price</th>\n",
       "      <th>place_sentiment</th>\n",
       "      <th>baked</th>\n",
       "      <th>lunch</th>\n",
       "      <th>breakfast</th>\n",
       "      <th>snacks</th>\n",
       "      <th>food_sentiment</th>\n",
       "      <th>sentence_normalized</th>\n",
       "      <th>sum</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Réveille Coffee</td>\n",
       "      <td>1.0 star rating</td>\n",
       "      <td>4/16/2019</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.026689</td>\n",
       "      <td>0.013172</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.028212</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028748</td>\n",
       "      <td>0.240632</td>\n",
       "      <td>0.051900</td>\n",
       "      <td>0.027582</td>\n",
       "      <td>0.046318</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Folks, avoid this place unless you like being ...</td>\n",
       "      <td>0.643034</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Réveille Coffee</td>\n",
       "      <td>1.0 star rating</td>\n",
       "      <td>4/16/2019</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.021167</td>\n",
       "      <td>0.029506</td>\n",
       "      <td>0.029123</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019126</td>\n",
       "      <td>0.076232</td>\n",
       "      <td>0.025603</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.097037</td>\n",
       "      <td>I went for a quick cappuccino only since they...</td>\n",
       "      <td>0.343937</td>\n",
       "      <td>0.144444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Réveille Coffee</td>\n",
       "      <td>1.0 star rating</td>\n",
       "      <td>4/16/2019</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.036137</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.025466</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015679</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>The girl behind the counter walked over and s...</td>\n",
       "      <td>0.077282</td>\n",
       "      <td>-0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>Réveille Coffee</td>\n",
       "      <td>1.0 star rating</td>\n",
       "      <td>4/16/2019</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031296</td>\n",
       "      <td>0.030890</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>I said hello</td>\n",
       "      <td>0.062186</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>Réveille Coffee</td>\n",
       "      <td>1.0 star rating</td>\n",
       "      <td>4/16/2019</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.056433</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>again nothing but a stare</td>\n",
       "      <td>0.056433</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id review           coffee           rating       date  beans     roast  \\\n",
       "0          0  Réveille Coffee  1.0 star rating  4/16/2019    0.0  0.000000   \n",
       "1          0  Réveille Coffee  1.0 star rating  4/16/2019    0.0  0.021167   \n",
       "2          0  Réveille Coffee  1.0 star rating  4/16/2019    0.0  0.000000   \n",
       "6          0  Réveille Coffee  1.0 star rating  4/16/2019    0.0  0.000000   \n",
       "9          0  Réveille Coffee  1.0 star rating  4/16/2019    0.0  0.000000   \n",
       "\n",
       "     drinks   barista  coffee_sentiment        go    ...        price  \\\n",
       "0  0.026689  0.013172               0.0  0.028212    ...     0.028748   \n",
       "1  0.029506  0.029123               0.0  0.000000    ...     0.000000   \n",
       "2  0.036137  0.000000               0.0  0.025466    ...     0.000000   \n",
       "6  0.031296  0.030890               0.0  0.000000    ...     0.000000   \n",
       "9  0.000000  0.000000               0.0  0.000000    ...     0.000000   \n",
       "\n",
       "   place_sentiment     baked     lunch  breakfast  snacks  food_sentiment  \\\n",
       "0         0.240632  0.051900  0.027582   0.046318     0.0        0.000000   \n",
       "1         0.000000  0.019126  0.076232   0.025603     0.0        0.097037   \n",
       "2         0.000000  0.000000  0.000000   0.015679     0.0        0.000000   \n",
       "6         0.000000  0.000000  0.000000   0.000000     0.0        0.000000   \n",
       "9         0.056433  0.000000  0.000000   0.000000     0.0        0.000000   \n",
       "\n",
       "                                 sentence_normalized       sum  polarity  \n",
       "0  Folks, avoid this place unless you like being ...  0.643034  0.000000  \n",
       "1   I went for a quick cappuccino only since they...  0.343937  0.144444  \n",
       "2   The girl behind the counter walked over and s...  0.077282 -0.400000  \n",
       "6                                       I said hello  0.062186  0.000000  \n",
       "9                          again nothing but a stare  0.056433  0.000000  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rescaling the polarity pattern scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_old = 1\n",
    "max_new = 1\n",
    "min_old = -1\n",
    "min_new = 0\n",
    "\n",
    "df_sc['polarity'] = df_sc['polarity'].apply(lambda v:((max_new - min_new)/(max_old - min_old))*(v - max_old) + max_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weighting the features calculated previously using similarity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_polarity_vector = df_sc[['beans','roast','drinks','barista',\\\n",
    "                            'coffee_sentiment','go','do','out',\\\n",
    "                            'ambient','price','place_sentiment',\n",
    "                            'baked','lunch','breakfast','snacks',\\\n",
    "                            'food_sentiment']].multiply(df_sc['polarity'], axis=\"index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transforming the rating column to float:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_polarity_vector['id review'] = df_sc['id review']\n",
    "df_polarity_vector['rating'] = df_sc['rating'].str.split(' star rating').str.get(0).astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group sentences by id review:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_polarity_vector[df_polarity_vector == 0] = np.nan\n",
    "df_polarity_vector = df_polarity_vector.groupby('id review').mean()\n",
    "df_polarity_vector = df_polarity_vector.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the dataFrame in the folder **preprocessing_ml** as **features_extended_vectors.csv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_polarity_vector.to_csv('preprocessing_ml/features_extended_vectors.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
